{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivianyz/transatlantic_voyagers/blob/main/ml_model_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12477a9",
      "metadata": {
        "id": "b12477a9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from flask import Flask, request, render_template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b982ed",
      "metadata": {
        "id": "e5b982ed"
      },
      "source": [
        "# Joining Tables and Preparing Data\n",
        "To build a comprehensive dataset for analysis or machine learning, data from multiple related tables must be combined. This process involves joining tables on shared keys or identifiers and selecting relevant columns for the task at hand.\n",
        "1. **Load CSV Files**: Start by loading the data from CSV files into pandas DataFrames. Each CSV file typically represents a table in your dataset, such as `ttav_passengers.csv`, `ttav_voyages.csv`, `ttav_routes.csv`, and `ttav_occupations.csv`.\n",
        "\n",
        "2. **Join Tables on Unique IDs**:\n",
        "   - **Passengers and Voyages**: Join the `ttav_passengers` table with the `ttav_voyages` table on the `MID` column to combine voyage information with passenger details.\n",
        "   - **Voyages and Routes**: Further join the above result with the `ttav_routes` table on the `routeID` to include routing details.\n",
        "   - **Comprehensive Join**: Finally, join the combined table with the `ttav_occupations` table on the `occID` to add occupation information for each passenger.\n",
        "\n",
        "3. **Select Relevant Columns**: From the fully joined table, select columns essential for the analysis or machine learning model. In this case, columns like `MID`, `routeID`, `age`, `sex`, `occID`, and `port_arv` are chosen for predicting the port of arrival based on passenger attributes.\n",
        "\n",
        "4. **Handle Missing Values**: Before proceeding with analysis or model training, ensure to handle any missing values in the selected columns to maintain data integrity and model accuracy.\n",
        "\n",
        "5. **Final Combined DataFrame**: The result of these steps is a comprehensive DataFrame that integrates information from multiple sources, ready for data analysis or as input to a machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04601075",
      "metadata": {
        "id": "04601075",
        "outputId": "584d7dd9-03d9-491a-e91b-8a4002fb24b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MID</th>\n",
              "      <th>routeID</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occID</th>\n",
              "      <th>occ_nm</th>\n",
              "      <th>occ_ctg</th>\n",
              "      <th>occ_grp</th>\n",
              "      <th>port_arv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82425</td>\n",
              "      <td>137</td>\n",
              "      <td>29.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43623</td>\n",
              "      <td>137</td>\n",
              "      <td>23.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44468</td>\n",
              "      <td>137</td>\n",
              "      <td>24.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60275</td>\n",
              "      <td>68</td>\n",
              "      <td>38.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43660</td>\n",
              "      <td>68</td>\n",
              "      <td>30.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     MID  routeID   age sex  occID        occ_nm        occ_ctg  \\\n",
              "0  82425      137  29.0   M    579  STORE KEEPER  Trade overall   \n",
              "1  43623      137  23.0   M    579  STORE KEEPER  Trade overall   \n",
              "2  44468      137  24.0   M    579  STORE KEEPER  Trade overall   \n",
              "3  60275       68  38.0   M    579  STORE KEEPER  Trade overall   \n",
              "4  43660       68  30.0   M    579  STORE KEEPER  Trade overall   \n",
              "\n",
              "              occ_grp  port_arv  \n",
              "0  Trade and commerce  New York  \n",
              "1  Trade and commerce  New York  \n",
              "2  Trade and commerce  New York  \n",
              "3  Trade and commerce  New York  \n",
              "4  Trade and commerce  New York  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the path to the dataverse_files directory\n",
        "path_to_files = './dataverse_files/'\n",
        "\n",
        "# Load the CSV files into pandas DataFrames\n",
        "passengers_df = pd.read_csv(f'{path_to_files}ttav_passengers.csv')\n",
        "voyages_df = pd.read_csv(f'{path_to_files}ttav_voyages.csv')\n",
        "routes_df = pd.read_csv(f'{path_to_files}ttav_routes.csv')\n",
        "occupations_df = pd.read_csv(f'{path_to_files}ttav_occupations.csv')\n",
        "\n",
        "# Perform the joins\n",
        "passengers_voyages_df = pd.merge(passengers_df, voyages_df, on='MID')\n",
        "voyages_routes_df = pd.merge(passengers_voyages_df, routes_df, on='routeID')\n",
        "final_df = pd.merge(voyages_routes_df, occupations_df, on='occID')\n",
        "\n",
        "# Select only the required columns\n",
        "final_df = final_df[['MID', 'routeID', 'age', 'sex', 'occID','occ_nm','occ_ctg','occ_grp','port_arv']]\n",
        "#Display the first few rows of the final DataFrame\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0541ad66",
      "metadata": {
        "id": "0541ad66"
      },
      "source": [
        "# Data Preprocessing\n",
        "Before building the machine learning model, the dataset requires preprocessing to ensure it's in the right format for the model to interpret. This includes handling missing values and encoding categorical variables.\n",
        "1. **Encode Categorical Variables**: Convert categorical variables into a format that can be provided to machine learning algorithms. This step includes encoding the `sex` column using label encoding.\n",
        "2. **Handle Missing Values**: Use `SimpleImputer` to fill in missing values. For numerical columns like `age` and `occID`, missing values are replaced with the median of the column.\n",
        "3. **Prepare Features and Target Variable**: Select the relevant columns (`age`, `sex`, `occID`) as features (X) and the column to predict (`port_arv`) as the target variable (y).\n",
        "4. **Split the Dataset**: Divide the dataset into training and testing sets to evaluate the model's performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d96925",
      "metadata": {
        "id": "e4d96925",
        "outputId": "f5b60ea3-0006-453c-a53a-c3cb5c07814c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9279761848329999\n",
            "['New York' 'New York' 'New York' ... 'New York' 'New York' 'New York']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.01      0.01      4461\n",
            "           1       0.13      0.01      0.01      1315\n",
            "           2       0.33      0.04      0.08        47\n",
            "           3       0.93      1.00      0.96     97962\n",
            "           4       0.50      0.01      0.02      1694\n",
            "\n",
            "    accuracy                           0.93    105479\n",
            "   macro avg       0.43      0.21      0.22    105479\n",
            "weighted avg       0.88      0.93      0.89    105479\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Encode the 'sex' column if it's categorical. If it's numeric, you can skip this step.\n",
        "label_encoder = LabelEncoder()\n",
        "final_df['encoded_sex'] = label_encoder.fit_transform(final_df['sex'].astype(str))\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = final_df[['age', 'encoded_sex', 'occID']].copy()  # Work on a copy to avoid changing the original DataFrame\n",
        "y = final_df['port_arv']\n",
        "\n",
        "# Impute missing values for 'age' and 'occID' (assuming they are numerical)\n",
        "# Adjust according to your dataset's needs\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X[['age', 'occID']] = imputer.fit_transform(X[['age', 'occID']])\n",
        "\n",
        "# Now, we also need to ensure that 'port_arv' is encoded\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Decision Tree Model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "decoded_prediction = label_encoder.inverse_transform(y_pred)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(decoded_prediction)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Now, your model is ready to make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad30668",
      "metadata": {
        "id": "cad30668",
        "outputId": "cb582108-2343-4845-eaf2-69978d4793e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MID</th>\n",
              "      <th>routeID</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>occID</th>\n",
              "      <th>occ_nm</th>\n",
              "      <th>occ_ctg</th>\n",
              "      <th>occ_grp</th>\n",
              "      <th>port_arv</th>\n",
              "      <th>encoded_sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82425</td>\n",
              "      <td>137</td>\n",
              "      <td>29.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43623</td>\n",
              "      <td>137</td>\n",
              "      <td>23.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44468</td>\n",
              "      <td>137</td>\n",
              "      <td>24.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60275</td>\n",
              "      <td>68</td>\n",
              "      <td>38.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43660</td>\n",
              "      <td>68</td>\n",
              "      <td>30.0</td>\n",
              "      <td>M</td>\n",
              "      <td>579</td>\n",
              "      <td>STORE KEEPER</td>\n",
              "      <td>Trade overall</td>\n",
              "      <td>Trade and commerce</td>\n",
              "      <td>New York</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     MID  routeID   age sex  occID        occ_nm        occ_ctg  \\\n",
              "0  82425      137  29.0   M    579  STORE KEEPER  Trade overall   \n",
              "1  43623      137  23.0   M    579  STORE KEEPER  Trade overall   \n",
              "2  44468      137  24.0   M    579  STORE KEEPER  Trade overall   \n",
              "3  60275       68  38.0   M    579  STORE KEEPER  Trade overall   \n",
              "4  43660       68  30.0   M    579  STORE KEEPER  Trade overall   \n",
              "\n",
              "              occ_grp  port_arv  encoded_sex  \n",
              "0  Trade and commerce  New York            1  \n",
              "1  Trade and commerce  New York            1  \n",
              "2  Trade and commerce  New York            1  \n",
              "3  Trade and commerce  New York            1  \n",
              "4  Trade and commerce  New York            1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e73260",
      "metadata": {
        "id": "46e73260",
        "outputId": "b51b01fd-93e4-4b70-d878-fa9f1286ed93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Count  Percentage\n",
            "New York      490473   92.999352\n",
            "Baltimore      22084    4.187382\n",
            "Philadelphia    8190    1.552919\n",
            "Boston          6390    1.211618\n",
            "New Orleans      257    0.048730\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming final_df is your DataFrame and it has a 'port_arv' column\n",
        "\n",
        "# Count the frequency of each distinct value in 'port_arv'\n",
        "port_arv_counts = final_df['port_arv'].value_counts()\n",
        "\n",
        "# Calculate the percentage of each distinct value\n",
        "port_arv_percentages = final_df['port_arv'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Combine both counts and percentages into a single DataFrame for easy viewing\n",
        "port_arv_summary = pd.DataFrame({\n",
        "    'Count': port_arv_counts,\n",
        "    'Percentage': port_arv_percentages\n",
        "})\n",
        "\n",
        "# Display the summary DataFrame\n",
        "print(port_arv_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8abe3db",
      "metadata": {
        "id": "e8abe3db"
      },
      "source": [
        "### Model Training and Evaluation\n",
        "\n",
        "After preprocessing the data, the next step is to train the decision tree model and evaluate its performance.\n",
        "\n",
        "1. **Train the Decision Tree Model**: A `DecisionTreeClassifier` is used to fit the model on the training data. The model learns to predict the `port_arv` based on the features `age`, `sex`, and `occID`.\n",
        "2. **Evaluate the Model**: Use the testing set to evaluate the model's accuracy and overall performance. This step involves comparing the predicted values of `port_arv` against the actual values in the test dataset.\n",
        "3. **Accuracy and Classification Report**: The model's performance is summarized through the following metrics, providing insight into its predictive capabilities and areas for improvement:\n",
        "\n",
        "    - **Accuracy**:\n",
        "        - *Definition*: The ratio of correctly predicted instances to the total instances in the dataset.\n",
        "        - *Interpretation*: High accuracy means that the model correctly predicted many of the outcomes. However, it might not be reliable in the presence of class imbalance.\n",
        "        - *Example*: If a model correctly predicts 950 out of 1000 instances, its accuracy is 95%.\n",
        "    \n",
        "    - **Precision**:\n",
        "        - *Definition*: The ratio of true positive predictions to the total positive predictions made for a given class.\n",
        "        - *Interpretation*: Precision is important when the cost of a false positive is high.\n",
        "        - *Example*: If a model predicts 100 instances as class 1, but only 90 are actually class 1, the precision for class 1 is 90%.\n",
        "\n",
        "    - **Recall**:\n",
        "        - *Definition*: The ratio of true positive predictions to the total actual positives for a given class.\n",
        "        - *Interpretation*: Recall is crucial when the cost of a false negative is high.\n",
        "        - *Example*: If there are 120 actual instances of class 1 and the model correctly identifies 90, the recall for class 1 is 75%.\n",
        "\n",
        "    - **F1-Score**:\n",
        "        - *Definition*: The harmonic mean of precision and recall.\n",
        "        - *Interpretation*: The F1-score is useful when you want to find a balance between precision and recall.\n",
        "        - *Example*: If the precision is 90% and recall is 75% for class 1, the F1-score would be approximately 82%.\n",
        "\n",
        "    - **Support**:\n",
        "        - *Definition*: The number of actual occurrences of the class in the specified dataset.\n",
        "        - *Interpretation*: Indicates the prevalence of each class in the dataset. Useful for identifying class imbalance.\n",
        "        - *Example*: If class 1 appears 120 times in the dataset, the support for class 1 is 120.\n",
        "\n",
        "    - **Macro Average**:\n",
        "        - *Definition*: The average of the metric computed independently for each class.\n",
        "        - *Interpretation*: Treats all classes equally, not considering their support.\n",
        "        - *Example*: If there are five classes, the macro average precision would be the average of the precision scores for each class.\n",
        "\n",
        "    - **Weighted Average**:\n",
        "        - *Definition*: The average of the metric weighted by the support of each class.\n",
        "        - *Interpretation*: Accounts for class imbalance by weighting the metric by the number of true instances for each class.\n",
        "        - *Example*: If class 1 has a support of 120 and a precision of 90%, while class 2 has a support of 30 and a precision of 60%, the weighted average precision would give more importance to the precision of class 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e80578a",
      "metadata": {
        "id": "8e80578a"
      },
      "source": [
        "# Why Use a Decision Tree Model\n",
        "\n",
        "Using a Decision Tree model for predicting `port_arv` based on features like `age`, `sex`, and `occID` from the dataset offers several advantages, making it a suitable choice for our scenario:\n",
        "\n",
        "## 1. Interpretability\n",
        "Decision Trees are highly interpretable models. They allow an easy understanding of how decisions are made, showing clear decision paths from features to outcomes. This is beneficial for explaining model predictions.\n",
        "\n",
        "## 2. Handling of Categorical Variables\n",
        "Decision Trees can directly handle categorical variables, making them a convenient choice given that our dataset includes categorical features like `sex` and `occID`.\n",
        "\n",
        "## 3. Non-linear Relationships\n",
        "They are capable of capturing non-linear relationships between features and the target variable, accommodating complex patterns in data.\n",
        "\n",
        "## 4. No Need for Feature Scaling\n",
        "Unlike some other models, Decision Trees do not require input features to be scaled or normalized. This simplifies the data preprocessing steps.\n",
        "\n",
        "## 5. Modeling Complex Decision Boundaries\n",
        "Decision Trees can model complex decision boundaries by learning a hierarchy of if-else questions, making them capable of understanding complicated relationships in the data.\n",
        "\n",
        "## 6. Fast Prediction Time\n",
        "After training, Decision Trees can make predictions quickly, as it only involves traversing the tree, which can be crucial for time-sensitive applications.\n",
        "\n",
        "## Limitations\n",
        "While Decision Trees have many benefits, they can be prone to overfitting, especially with complex data and without constraints on tree depth. Overfitting can be addressed by pruning the tree or using ensemble methods like Random Forests, which improve generalization by averaging multiple trees' predictions.\n",
        "\n",
        "In conclusion, a Decision Tree is an excellent starting point due to its interpretability, ease of handling categorical data, and flexibility in modeling complex relationships. Nonetheless, it's essential to assess its performance against other models and consider ensemble techniques if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb85fce1",
      "metadata": {
        "id": "fb85fce1",
        "outputId": "ad8fd14e-f637-4afe-d617-bd4945a3229b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9279761848329999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.01      0.01      4461\n",
            "           1       0.13      0.01      0.01      1315\n",
            "           2       0.33      0.04      0.08        47\n",
            "           3       0.93      1.00      0.96     97962\n",
            "           4       0.50      0.01      0.02      1694\n",
            "\n",
            "    accuracy                           0.93    105479\n",
            "   macro avg       0.43      0.21      0.22    105479\n",
            "weighted avg       0.88      0.93      0.89    105479\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the Decision Tree Model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Now, the model is ready to make simulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85dde549",
      "metadata": {
        "id": "85dde549",
        "outputId": "756cd600-723b-4d0c-ff54-33e8f99eb459"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['decision_tree_model.joblib']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(model, 'decision_tree_model.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16286e9",
      "metadata": {
        "id": "c16286e9",
        "outputId": "31f11ab1-2333-4671-d4ae-89e272c4d427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['port_arv_encoder.joblib']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'sex' and 'port_arv' are columns in final_df\n",
        "sex_encoder = LabelEncoder()\n",
        "port_arv_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the columns\n",
        "final_df['sex_encoded'] = sex_encoder.fit_transform(final_df['sex'])\n",
        "final_df['port_arv_encoded'] = port_arv_encoder.fit_transform(final_df['port_arv'])\n",
        "\n",
        "# Now, you use 'sex_encoded' and 'port_arv_encoded' for training the model...\n",
        "# After training, save your model and encoders:\n",
        "joblib.dump(sex_encoder, 'sex_encoder.joblib')\n",
        "joblib.dump(port_arv_encoder, 'port_arv_encoder.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45884184",
      "metadata": {
        "id": "45884184",
        "outputId": "2a706989-f195-4b2f-95a1-f9d5c5ca325f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['port_arv_encoder.joblib']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'sex' and 'port_arv' are columns in final_df\n",
        "sex_encoder = LabelEncoder()\n",
        "port_arv_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the columns\n",
        "final_df['sex_encoded'] = sex_encoder.fit_transform(final_df['sex'])\n",
        "final_df['port_arv_encoded'] = port_arv_encoder.fit_transform(final_df['port_arv'])\n",
        "\n",
        "# Now, you use 'sex_encoded' and 'port_arv_encoded' for training the model...\n",
        "# After training, save your model and encoders:\n",
        "joblib.dump(sex_encoder, 'sex_encoder.joblib')\n",
        "joblib.dump(port_arv_encoder, 'port_arv_encoder.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d59839",
      "metadata": {
        "id": "27d59839"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "port_arv_encoder = joblib.load('port_arv_encoder.joblib')\n",
        "\n",
        "\n",
        "# Map occupation names to IDs\n",
        "occ_nm_to_id = occupations_df.set_index('occ_nm')['occID'].to_dict()\n",
        "occ_names = list(occ_nm_to_id.keys())\n",
        "\n",
        "# Map 'sex' to 'encoded_sex'\n",
        "sex_to_encoded = final_df[['sex', 'encoded_sex']].drop_duplicates().set_index('sex')['encoded_sex'].to_dict()\n",
        "\n",
        "def predict():\n",
        "    age = int(age_entry.get())\n",
        "    sex = sex_combobox.get()\n",
        "    occ_nm = occ_nm_combobox.get()\n",
        "    occID = occ_nm_to_id[occ_nm]\n",
        "\n",
        "    # Encode sex\n",
        "    encoded_sex = sex_to_encoded[sex]\n",
        "    #print(encoded_sex)\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = model.predict(pd.DataFrame([[age, encoded_sex, occID]], columns=['age', 'encoded_sex', 'occID']))\n",
        "\n",
        "    # Decode the port_arv prediction\n",
        "    decoded_port_arv = port_arv_encoder.inverse_transform(prediction)[0]\n",
        "\n",
        "    result_label.config(text=f\"Simulated Port of Arrival: {decoded_port_arv}\")\n",
        "\n",
        "app = tk.Tk()\n",
        "app.title(\"Arrival Port Simulation\")\n",
        "\n",
        "tk.Label(app, text=\"Please enter your age, sex, and occupation info:\").pack()\n",
        "\n",
        "tk.Label(app, text=\"Age:\").pack()\n",
        "age_entry = tk.Entry(app)\n",
        "age_entry.pack()\n",
        "\n",
        "tk.Label(app, text=\"Sex:\").pack()\n",
        "sex_combobox = ttk.Combobox(app, values=['M', 'F'])\n",
        "sex_combobox.pack()\n",
        "\n",
        "tk.Label(app, text=\"Occupation:\").pack()\n",
        "occ_nm_combobox = ttk.Combobox(app, values=occ_names)\n",
        "occ_nm_combobox.pack()\n",
        "predict_button = tk.Button(app, text=\"Simulate\", command=predict)\n",
        "predict_button.pack()\n",
        "\n",
        "result_label = tk.Label(app, text=\"Port of Arrival will be shown here.\")\n",
        "result_label.pack()\n",
        "\n",
        "app.mainloop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}